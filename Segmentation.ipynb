{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ec8e11"
      },
      "source": [
        "# Medical Image Segmentation using AI Models\n",
        "\n",
        "This notebook demonstrates how to perform whole-body CT segmentation using two different AI models: TotalSegmentator and MedIm.\n",
        "\n",
        "---\n",
        "\n",
        "## Part 1: Data Preparation\n",
        "\n",
        "This section handles the download and extraction of the dataset required for the segmentation tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b077c0e"
      },
      "source": [
        "This cell installs the necessary libraries, downloads a sample CT scan dataset from a Google Drive link using `gdown`, and then unzips the downloaded archive. The dataset contains CT images and corresponding segmentations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6e39ed3"
      },
      "source": [
        "!pip install gdown\n",
        "!gdown --id 1no_qpQSWioNIu5CChE0bnNldkiY63dgg\n",
        "!unzip CT_subset_big.zip\n",
        "\n",
        "!pip install --quiet nibabel numpy scipy scikit-image matplotlib totalsegmentator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58f44e98"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: TotalSegmentator\n",
        "\n",
        "This section utilizes the TotalSegmentator library, a widely used tool for automatic segmentation of various organs and structures in CT scans."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cd4a371"
      },
      "source": [
        "This cell performs a comprehensive total body segmentation on the downloaded CT scan using the `totalsegmentator` library. It first sets up the input and output paths, then cleans up any previous output directory. The `totalsegmentator` function is called with options to save individual organ segmentations and use the more accurate segmentation mode. Finally, it includes a function to remove any generated segmentation files that are found to be completely empty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32bb88d"
      },
      "source": [
        "import shutil\n",
        "from totalsegmentator.python_api import totalsegmentator\n",
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to the input CT scan file\n",
        "input_file = '/content/s0010/ct.nii.gz'\n",
        "\n",
        "# Set the name for the output directory where segmentations will be saved\n",
        "output_dir_total = \"TotalSegmentator_Output\"\n",
        "\n",
        "# Clean up the output directory if it already exists\n",
        "if os.path.exists(output_dir_total):\n",
        "    shutil.rmtree(output_dir_total)\n",
        "    print(f\"Previous output directory removed: {output_dir_total}\")\n",
        "else:\n",
        "    print(f\"Output directory not found, proceeding with creation: {output_dir_total}\")\n",
        "\n",
        "# Create the output directory to store the segmentation results\n",
        "os.makedirs(output_dir_total, exist_ok=True)\n",
        "\n",
        "# Execute TotalSegmentator to perform segmentation on the input scan\n",
        "print(f\"Initiating TotalSegmentator for comprehensive segmentation...\")\n",
        "totalsegmentator(\n",
        "    input=input_file,\n",
        "    output=output_dir_total,\n",
        "    ml=False,               # Option to save individual organ segmentations\n",
        "    task=\"total\",           # Specify the task to segment all structures\n",
        "    fast=False,             # Use the more accurate segmentation mode\n",
        "    preview=False,          # Disable quick preview segmentation\n",
        "    output_type=\"niftigz\"   # Ensure output files are in compressed NIfTI format\n",
        ")\n",
        "print(f\"Segmentation process completed! Results are in: {output_dir_total}\")\n",
        "\n",
        "# Optional step: Remove any generated segmentation files that are completely empty\n",
        "def filter_empty_files(output_dir):\n",
        "    print(\"\\nChecking for and removing empty segmentation files...\")\n",
        "    for root, dirs, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.nii.gz'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    img = nib.load(file_path)\n",
        "                    data = img.get_fdata()\n",
        "                    if np.sum(data) == 0:\n",
        "                        print(f\"Identified and removing empty file: {file_path}\")\n",
        "                        os.remove(file_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"An error occurred while processing file {file_path}: {e}\")\n",
        "\n",
        "filter_empty_files(output_dir_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "928a0d67"
      },
      "source": [
        "This cell compresses the output directory generated by TotalSegmentator into a zip file named `TotalSegmentator_Output.zip`. It then provides a download link for this zip file, allowing you to easily access the segmentation results on your local machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "048a5500"
      },
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Zip the output directory\n",
        "shutil.make_archive(output_dir_total, 'zip', output_dir_total)\n",
        "\n",
        "# Download the zipped directory\n",
        "files.download(f'{output_dir_total}.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bd5aacf"
      },
      "source": [
        "* * *\n",
        "\n",
        "## Part 3: Wholebody CT Segmentation Model\n",
        "\n",
        "This section uses the wholebody CT segmentation pre-trained model from the MONAI Model Zoo. It covers the steps of downloading and loading the model, preprocessing the input image, performing the segmentation inference, and saving the resulting organ masks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and modules for the \"wholebody ct segemntation\" AI Model\n",
        "!pip install -q monai[all]\n",
        "!pip install -q nibabel\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import shutil\n",
        "from monai.bundle import download, load\n",
        "from monai.transforms import (\n",
        "    LoadImage,\n",
        "    EnsureChannelFirst,\n",
        "    ScaleIntensity,\n",
        "    Orientation,\n",
        "    CropForeground,\n",
        "    DivisiblePad,\n",
        "    EnsureType\n",
        ")\n",
        "\n",
        "# Download the MONAI whole body CT segmentation model\n",
        "bundle_name = \"wholeBody_ct_segmentation\"\n",
        "\n",
        "# Download the model bundle (from MONAI Model Zoo)\n",
        "bundle_dir = download(name=bundle_name, source=\"github\", progress=True)\n",
        "print(f\"Model download complete: {bundle_dir}\")\n",
        "\n",
        "# Load the downloaded model\n",
        "model = load(name=bundle_name, bundle_dir=bundle_dir)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Specify the path to the input CT scan file\n",
        "input_path = \"/content/s0010/ct.nii.gz\"\n",
        "\n",
        "# Verify the input file exists\n",
        "if not os.path.exists(input_path):\n",
        "    print(f\"Input file not found: {input_path}\")\n",
        "    print(\"Ensure your CT scan is located at /content/s0010/ct.nii.gz\")\n",
        "    print(\"\\nFile upload options:\")\n",
        "    print(\"1. Direct upload:\")\n",
        "    print(\"   !mkdir -p /content/s0010\")\n",
        "    print(\"   from google.colab import files\")\n",
        "    print(\"   uploaded = files.upload()\")\n",
        "    print(\"   !mv uploaded_file.nii.gz /content/s0010/ct.nii.gz\")\n",
        "    print(\"\\n2. Mount Google Drive:\")\n",
        "    print(\"   from google.colab import drive\")\n",
        "    print(\"   drive.mount('/content/drive')\")\n",
        "    print(\"   !cp /content/drive/MyDrive/path/to/ct.nii.gz /content/s0010/ct.nii.gz\")\n",
        "else:\n",
        "    print(f\"Input file found: {input_path}\")\n",
        "\n",
        "# Define and create the output directory\n",
        "output_dir = \"/content/wholebody_ct_segmentation\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load and preprocess the input image\n",
        "loader = LoadImage(image_only=True)\n",
        "image = loader(input_path)\n",
        "\n",
        "# Define image transformations\n",
        "transforms = [\n",
        "    EnsureChannelFirst(),\n",
        "    ScaleIntensity(),\n",
        "    Orientation(axcodes=\"RAS\"),\n",
        "    CropForeground(),\n",
        "    DivisiblePad(k=96),\n",
        "    EnsureType()\n",
        "]\n",
        "\n",
        "# Apply transformations to the image\n",
        "for t in transforms:\n",
        "    image = t(image)\n",
        "\n",
        "image = image.unsqueeze(0).float().to(device)\n",
        "print(f\"Processed image shape: {image.shape}\")\n",
        "\n",
        "# Perform segmentation using sliding window inference\n",
        "from monai.inferers import sliding_window_inference\n",
        "\n",
        "print(\"Performing segmentation with sliding window...\")\n",
        "print(\"This process may take some time due to memory constraints.\")\n",
        "\n",
        "# Clear GPU cache before inference\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Run inference and store output on CPU\n",
        "with torch.no_grad():\n",
        "    output = sliding_window_inference(\n",
        "        inputs=image,\n",
        "        roi_size=(96, 96, 96),      # Patch size for processing\n",
        "        sw_batch_size=1,             # Batch size for sliding window\n",
        "        predictor=model,\n",
        "        overlap=0.5,                 # Overlap between patches\n",
        "        mode=\"gaussian\",             # Blending mode\n",
        "        device=torch.device(\"cpu\")   # Output device\n",
        "    )\n",
        "    output = torch.argmax(output, dim=1).cpu().numpy().squeeze()\n",
        "\n",
        "# Clear GPU cache after inference\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"Segmentation inference complete. Output shape: {output.shape}\")\n",
        "\n",
        "# Define organ labels mapping\n",
        "organ_labels = {\n",
        "    1: \"spleen\",\n",
        "    2: \"kidney_right\",\n",
        "    3: \"kidney_left\",\n",
        "    4: \"gallbladder\",\n",
        "    5: \"liver\",\n",
        "    6: \"stomach\",\n",
        "    7: \"aorta\",\n",
        "    8: \"inferior_vena_cava\",\n",
        "    9: \"portal_vein_and_splenic_vein\",\n",
        "    10: \"pancreas\",\n",
        "    11: \"adrenal_gland_right\",\n",
        "    12: \"adrenal_gland_left\",\n",
        "    13: \"lung_upper_lobe_left\",\n",
        "    14: \"lung_lower_lobe_left\",\n",
        "    15: \"lung_upper_lobe_right\",\n",
        "    16: \"lung_middle_lobe_right\",\n",
        "    17: \"lung_lower_lobe_right\",\n",
        "    18: \"vertebrae_L5\",\n",
        "    19: \"vertebrae_L4\",\n",
        "    20: \"vertebrae_L3\",\n",
        "    21: \"vertebrae_L2\",\n",
        "    22: \"vertebrae_L1\",\n",
        "    23: \"vertebrae_T12\",\n",
        "    24: \"vertebrae_T11\",\n",
        "    25: \"vertebrae_T10\",\n",
        "    26: \"vertebrae_T9\",\n",
        "    27: \"vertebrae_T8\",\n",
        "    28: \"vertebrae_T7\",\n",
        "    29: \"vertebrae_T6\",\n",
        "    30: \"vertebrae_T5\",\n",
        "    31: \"vertebrae_T4\",\n",
        "    32: \"vertebrae_T3\",\n",
        "    33: \"vertebrae_T2\",\n",
        "    34: \"vertebrae_T1\",\n",
        "    35: \"vertebrae_C7\",\n",
        "    36: \"vertebrae_C6\",\n",
        "    37: \"vertebrae_C5\",\n",
        "    38: \"vertebrae_C4\",\n",
        "    39: \"vertebrae_C3\",\n",
        "    40: \"vertebrae_C2\",\n",
        "    41: \"vertebrae_C1\",\n",
        "    42: \"esophagus\",\n",
        "    43: \"trachea\",\n",
        "    44: \"heart_myocardium\",\n",
        "    45: \"heart_atrium_left\",\n",
        "    46: \"heart_ventricle_left\",\n",
        "    47: \"heart_atrium_right\",\n",
        "    48: \"heart_ventricle_right\",\n",
        "    49: \"pulmonary_artery\",\n",
        "    50: \"brain\",\n",
        "    51: \"iliac_artery_left\",\n",
        "    52: \"iliac_artery_right\",\n",
        "    53: \"iliac_vena_left\",\n",
        "    54: \"iliac_vena_right\",\n",
        "    55: \"small_bowel\",\n",
        "    56: \"duodenum\",\n",
        "    57: \"colon\",\n",
        "    58: \"rib_left_1\",\n",
        "    59: \"rib_left_2\",\n",
        "    60: \"rib_left_3\",\n",
        "    61: \"rib_left_4\",\n",
        "    62: \"rib_left_5\",\n",
        "    63: \"rib_left_6\",\n",
        "    64: \"rib_left_7\",\n",
        "    65: \"rib_left_8\",\n",
        "    66: \"rib_left_9\",\n",
        "    67: \"rib_left_10\",\n",
        "    68: \"rib_left_11\",\n",
        "    69: \"rib_left_12\",\n",
        "    70: \"rib_right_1\",\n",
        "    71: \"rib_right_2\",\n",
        "    72: \"rib_right_3\",\n",
        "    73: \"rib_right_4\",\n",
        "    74: \"rib_right_5\",\n",
        "    75: \"rib_right_6\",\n",
        "    76: \"rib_right_7\",\n",
        "    77: \"rib_right_8\",\n",
        "    78: \"rib_right_9\",\n",
        "    79: \"rib_right_10\",\n",
        "    80: \"rib_right_11\",\n",
        "    81: \"rib_right_12\",\n",
        "    82: \"humerus_left\",\n",
        "    83: \"humerus_right\",\n",
        "84: \"scapula_left\",\n",
        "    85: \"scapula_right\",\n",
        "    86: \"clavicula_left\",\n",
        "    87: \"clavicula_right\",\n",
        "    88: \"femur_left\",\n",
        "    89: \"femur_right\",\n",
        "    90: \"hip_left\",\n",
        "    91: \"hip_right\",\n",
        "    92: \"sacrum\",\n",
        "    93: \"face\",\n",
        "    94: \"gluteus_maximus_left\",\n",
        "    95: \"gluteus_maximus_right\",\n",
        "    96: \"gluteus_medius_left\",\n",
        "    97: \"gluteus_medius_right\",\n",
        "    98: \"gluteus_minimus_left\",\n",
        "    99: \"gluteus_minimus_right\",\n",
        "    100: \"autochthon_left\",\n",
        "    101: \"autochthon_right\",\n",
        "    102: \"iliopsoas_left\",\n",
        "    103: \"iliopsoas_right\",\n",
        "    104: \"urinary_bladder\"\n",
        "}\n",
        "\n",
        "# Save individual organ masks\n",
        "nii = nib.load(input_path)\n",
        "affine, header = nii.affine, nii.header\n",
        "\n",
        "saved_count = 0\n",
        "for label_id, organ_name in organ_labels.items():\n",
        "    mask = (output == label_id).astype(np.uint8)\n",
        "\n",
        "    if np.sum(mask) == 0:\n",
        "        continue  # Skip empty organs\n",
        "\n",
        "    seg_img = nib.Nifti1Image(mask, affine, header)\n",
        "    out_file = os.path.join(output_dir, f\"{organ_name}.nii.gz\")\n",
        "    nib.save(seg_img, out_file)\n",
        "    saved_count += 1\n",
        "    print(f\"Saved: {organ_name}.nii.gz\")\n",
        "\n",
        "print(f\"\\nSegmentation process finished. {saved_count} organ masks were saved.\")\n",
        "\n",
        "# Download the results as a ZIP file\n",
        "!zip -r segmentation_results.zip {output_dir}\n",
        "files.download('segmentation_results.zip')\n",
        "\n",
        "# Option to download to Google Drive (uncomment to use)\n",
        "# import shutil\n",
        "# drive_output = \"/content/drive/MyDrive/segmentation_output\"\n",
        "# shutil.copytree(output_dir, drive_output)\n",
        "# print(f\"Results copied to Google Drive: {drive_output}\")"
      ],
      "metadata": {
        "id": "Sn9DdnbwiTOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ad2b7bd"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: MedIm Segmentation\n",
        "\n",
        "This section explores using the MedIm library for whole-body CT segmentation, showcasing a different model and workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80d419d6"
      },
      "source": [
        "This cell installs the `medim` library and its dependencies, then attempts to perform segmentation using a pre-trained STU-Net model from `medim`. It defines a mapping for anatomical structures, preprocesses the input CT scan by clipping, normalizing, resampling, and resizing. It then runs inference using the loaded model and postprocesses the output to save individual organ masks as NIfTI files with descriptive names, as well as a combined multi-label segmentation file. Error handling is included for model loading and processing steps, with a fallback to a basic STU-Net model if the primary one fails."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b78be7a"
      },
      "source": [
        "# Install MedIM and required dependencies\n",
        "!pip install medim\n",
        "!pip install nibabel numpy torch torchvision\n",
        "!pip install monai  # For medical image preprocessing utilities\n",
        "\n",
        "# TotalSegmentator organ class mapping (104 classes + background)\n",
        "# Based on TotalSegmentator v1 (104 anatomical structures)\n",
        "TOTALSEGMENTATOR_CLASS_MAPPING = {\n",
        "    0: \"background\",\n",
        "    1: \"spleen\",\n",
        "    2: \"kidney_right\",\n",
        "    3: \"kidney_left\",\n",
        "    4: \"gallbladder\",\n",
        "    5: \"liver\",\n",
        "    6: \"stomach\",\n",
        "    7: \"aorta\",\n",
        "    8: \"inferior_vena_cava\",\n",
        "    9: \"portal_vein_and_splenic_vein\",\n",
        "    10: \"pancreas\",\n",
        "    11: \"adrenal_gland_right\",\n",
        "    12: \"adrenal_gland_left\",\n",
        "    13: \"lung_upper_lobe_left\",\n",
        "    14: \"lung_lower_lobe_left\",\n",
        "    15: \"lung_upper_lobe_right\",\n",
        "    16: \"lung_middle_lobe_right\",\n",
        "    17: \"lung_lower_lobe_right\",\n",
        "    18: \"vertebrae_L5\",\n",
        "    19: \"vertebrae_L4\",\n",
        "    20: \"vertebrae_L3\",\n",
        "    21: \"vertebrae_L2\",\n",
        "    22: \"vertebrae_L1\",\n",
        "    23: \"vertebrae_T12\",\n",
        "    24: \"vertebrae_T11\",\n",
        "    25: \"vertebrae_T10\",\n",
        "    26: \"vertebrae_T9\",\n",
        "    27: \"vertebrae_T8\",\n",
        "    28: \"vertebrae_T7\",\n",
        "    29: \"vertebrae_T6\",\n",
        "    30: \"vertebrae_T5\",\n",
        "    31: \"vertebrae_T4\",\n",
        "    32: \"vertebrae_T3\",\n",
        "    33: \"vertebrae_T2\",\n",
        "    34: \"vertebrae_T1\",\n",
        "    35: \"vertebrae_C7\",\n",
        "    36: \"vertebrae_C6\",\n",
        "    37: \"vertebrae_C5\",\n",
        "    38: \"vertebrae_C4\",\n",
        "    39: \"vertebrae_C3\",\n",
        "    40: \"vertebrae_C2\",\n",
        "    41: \"vertebrae_C1\",\n",
        "    42: \"esophagus\",\n",
        "    43: \"trachea\",\n",
        "    44: \"heart_myocardium\",\n",
        "    45: \"heart_atrium_left\",\n",
        "    46: \"heart_ventricle_left\",\n",
        "    47: \"heart_ventricle_right\",\n",
        "    48: \"heart_atrium_right\",\n",
        "    49: \"pulmonary_artery\",\n",
        "    50: \"brain\",\n",
        "    51: \"iliac_artery_left\",\n",
        "    52: \"iliac_artery_right\",\n",
        "    53: \"iliac_vena_left\",\n",
        "    54: \"iliac_vena_right\",\n",
        "    55: \"small_bowel\",\n",
        "    56: \"duodenum\",\n",
        "    57: \"colon\",\n",
        "    58: \"rib_left_1\",\n",
        "    59: \"rib_left_2\",\n",
        "    60: \"rib_left_3\",\n",
        "    61: \"rib_left_4\",\n",
        "    62: \"rib_left_5\",\n",
        "    63: \"rib_left_6\",\n",
        "    64: \"rib_left_7\",\n",
        "    65: \"rib_left_8\",\n",
        "    66: \"rib_left_9\",\n",
        "    67: \"rib_left_10\",\n",
        "    68: \"rib_left_11\",\n",
        "    69: \"rib_left_12\",\n",
        "    70: \"rib_right_1\",\n",
        "    71: \"rib_right_2\",\n",
        "    72: \"rib_right_3\",\n",
        "    73: \"rib_right_4\",\n",
        "    74: \"rib_right_5\",\n",
        "    75: \"rib_right_6\",\n",
        "    76: \"rib_right_7\",\n",
        "    77: \"rib_right_8\",\n",
        "    78: \"rib_right_9\",\n",
        "    79: \"rib_right_10\",\n",
        "    80: \"rib_right_11\",\n",
        "    81: \"rib_right_12\",\n",
        "    82: \"humerus_left\",\n",
        "    83: \"humerus_right\",\n",
        "    84: \"scapula_left\",\n",
        "    85: \"scapula_right\",\n",
        "    86: \"clavicula_left\",\n",
        "    87: \"clavicula_right\",\n",
        "    88: \"femur_left\",\n",
        "    89: \"femur_right\",\n",
        "    90: \"hip_left\",\n",
        "    91: \"hip_right\",\n",
        "    92: \"sacrum\",\n",
        "    93: \"face\",\n",
        "    94: \"gluteus_maximus_left\",\n",
        "    95: \"gluteus_maximus_right\",\n",
        "    96: \"gluteus_medius_left\",\n",
        "    97: \"gluteus_medius_right\",\n",
        "    98: \"gluteus_minimus_left\",\n",
        "    99: \"gluteus_minimus_right\",\n",
        "    100: \"autochthon_left\",\n",
        "    101: \"autochthon_right\",\n",
        "    102: \"iliopsoas_left\",\n",
        "    103: \"iliopsoas_right\",\n",
        "    104: \"urinary_bladder\"\n",
        "}\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from scipy import ndimage\n",
        "import medim\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Input CT scan\n",
        "input_file = '/content/s0010/ct.nii.gz'\n",
        "\n",
        "# Define output directory\n",
        "output_dir_medim = \"MedIm\"\n",
        "\n",
        "# Remove existing output directory if it exists\n",
        "if os.path.exists(output_dir_medim):\n",
        "    shutil.rmtree(output_dir_medim)\n",
        "    print(f\"Removed directory: {output_dir_medim}\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(output_dir_medim, exist_ok=True)\n",
        "\n",
        "def preprocess_ct_scan(input_file, target_spacing=(1.5, 1.5, 1.5), target_size=(128, 128, 128)):\n",
        "    \"\"\"\n",
        "    Preprocess CT scan for MedIM STU-Net model\n",
        "    \"\"\"\n",
        "    print(\"Loading and preprocessing CT scan...\")\n",
        "\n",
        "    # Load NIfTI file\n",
        "    img = nib.load(input_file)\n",
        "    data = img.get_fdata().astype(np.float32)\n",
        "\n",
        "    # Get original spacing and affine\n",
        "    original_spacing = img.header.get_zooms()[:3]\n",
        "    affine = img.affine\n",
        "\n",
        "    print(f\"Original shape: {data.shape}\")\n",
        "    print(f\"Original spacing: {original_spacing}\")\n",
        "\n",
        "    # Clip HU values (typical CT range)\n",
        "    data = np.clip(data, -1024, 1024)\n",
        "\n",
        "    # Normalize to [0, 1] range\n",
        "    data = (data + 1024) / 2048.0\n",
        "\n",
        "    # Resample to target spacing if needed\n",
        "    if original_spacing != target_spacing:\n",
        "        zoom_factors = [orig/target for orig, target in zip(original_spacing, target_spacing)]\n",
        "        data = ndimage.zoom(data, zoom_factors, order=1, mode='nearest')\n",
        "        print(f\"Resampled shape: {data.shape}\")\n",
        "\n",
        "    # Resize to target size for model input\n",
        "    current_shape = data.shape\n",
        "    resize_factors = [target/current for target, current in zip(target_size, current_shape)]\n",
        "    data_resized = ndimage.zoom(data, resize_factors, order=1, mode='nearest')\n",
        "\n",
        "    print(f\"Final preprocessed shape: {data_resized.shape}\")\n",
        "\n",
        "    # Convert to tensor and add batch and channel dimensions\n",
        "    data_tensor = torch.from_numpy(data_resized).float()\n",
        "    data_tensor = data_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, H, W, D)\n",
        "\n",
        "    return data_tensor, data, current_shape, affine, img.header\n",
        "\n",
        "def postprocess_segmentation(pred_tensor, original_shape, original_affine, original_header, output_dir):\n",
        "    \"\"\"\n",
        "    Postprocess segmentation results and save individual organ masks with proper names\n",
        "    \"\"\"\n",
        "    print(\"Postprocessing segmentation results...\")\n",
        "\n",
        "    # Remove batch dimension and convert to numpy\n",
        "    pred_np = pred_tensor.squeeze(0).cpu().numpy()  # (num_classes, H, W, D)\n",
        "\n",
        "    # Get number of classes\n",
        "    num_classes = pred_np.shape[0]\n",
        "    print(f\"Number of segmented classes: {num_classes}\")\n",
        "\n",
        "    # Resize back to original CT scan dimensions\n",
        "    resize_factors = [orig/current for orig, current in zip(original_shape, pred_np.shape[1:])]\n",
        "\n",
        "    # Create a multi-label segmentation volume\n",
        "    multi_label_seg = np.zeros(original_shape, dtype=np.uint16)\n",
        "\n",
        "    # Keep track of saved organs\n",
        "    saved_organs = []\n",
        "\n",
        "    # Process each class\n",
        "    for class_idx in range(num_classes):\n",
        "        if class_idx == 0:  # Skip background class\n",
        "            continue\n",
        "\n",
        "        # Get class probability map\n",
        "        class_prob = pred_np[class_idx]\n",
        "\n",
        "        # Resize to original dimensions\n",
        "        class_resized = ndimage.zoom(class_prob, resize_factors, order=1, mode='nearest')\n",
        "\n",
        "        # Threshold to get binary mask (adjust threshold as needed)\n",
        "        class_mask = (class_resized > 0.5).astype(np.uint16)\n",
        "\n",
        "        # Add to multi-label volume\n",
        "        multi_label_seg[class_mask > 0] = class_idx\n",
        "\n",
        "        # Save individual organ mask with proper name\n",
        "        if np.sum(class_mask) > 0:  # Only save non-empty masks\n",
        "            # Get organ name from mapping\n",
        "            organ_name = TOTALSEGMENTATOR_CLASS_MAPPING.get(class_idx, f\"unknown_class_{class_idx}\")\n",
        "\n",
        "            organ_img = nib.Nifti1Image(class_mask, original_affine, original_header)\n",
        "            organ_filename = os.path.join(output_dir, f\"{organ_name}.nii.gz\")\n",
        "            nib.save(organ_img, organ_filename)\n",
        "\n",
        "            voxel_count = np.sum(class_mask)\n",
        "            saved_organs.append((organ_name, voxel_count))\n",
        "            print(f\"Saved {organ_name}: {voxel_count} voxels\")\n",
        "\n",
        "    # Save multi-label segmentation\n",
        "    multi_label_img = nib.Nifti1Image(multi_label_seg, original_affine, original_header)\n",
        "    multi_label_filename = os.path.join(output_dir, \"segmentations.nii.gz\")\n",
        "    nib.save(multi_label_img, multi_label_filename)\n",
        "    print(f\"Saved multi-label segmentation: {multi_label_filename}\")\n",
        "\n",
        "    # Print summary of saved organs\n",
        "    print(f\"\\nSegmentation Summary:\")\n",
        "    print(f\"Total organs segmented: {len(saved_organs)}\")\n",
        "    print(\"Organs found:\")\n",
        "    for organ_name, voxel_count in sorted(saved_organs, key=lambda x: x[1], reverse=True):\n",
        "        print(f\"  - {organ_name}: {voxel_count:,} voxels\")\n",
        "\n",
        "    return multi_label_seg\n",
        "\n",
        "def run_medim_segmentation(input_file, output_dir):\n",
        "    \"\"\"\n",
        "    Main function to run MedIM segmentation\n",
        "    \"\"\"\n",
        "    print(\"Creating MedIM model...\")\n",
        "\n",
        "    # Create STU-Net model pre-trained on TotalSegmentator dataset\n",
        "    # This should give similar results to TotalSegmentator\n",
        "    model = medim.create_model(\"STU-Net-B\", dataset=\"TotalSegmentator\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "    # Preprocess input\n",
        "    input_tensor, original_data, original_shape, affine, header = preprocess_ct_scan(input_file)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    print(\"Running inference...\")\n",
        "    with torch.no_grad():\n",
        "        # Run inference\n",
        "        output = model(input_tensor)\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        if len(output.shape) == 5:  # (batch, classes, H, W, D)\n",
        "            output = torch.softmax(output, dim=1)\n",
        "\n",
        "    print(\"Inference completed!\")\n",
        "\n",
        "    # Postprocess and save results\n",
        "    segmentation_result = postprocess_segmentation(\n",
        "        output, original_shape, affine, header, output_dir\n",
        "    )\n",
        "\n",
        "    return segmentation_result\n",
        "\n",
        "# Run the segmentation\n",
        "print(f\"Running MedIM segmentation on: {input_file}\")\n",
        "try:\n",
        "    segmentation_result = run_medim_segmentation(input_file, output_dir_medim)\n",
        "    print(f\"Segmentation completed! Results saved in: {output_dir_medim}\")\n",
        "\n",
        "    # List generated files with proper names\n",
        "    print(\"\\nGenerated organ files:\")\n",
        "    organ_files = []\n",
        "    for file in os.listdir(output_dir_medim):\n",
        "        if file.endswith('.nii.gz') and file != 'segmentations.nii.gz':\n",
        "            file_path = os.path.join(output_dir_medim, file)\n",
        "            img = nib.load(file_path)\n",
        "            data = img.get_fdata()\n",
        "            non_zero_voxels = np.count_nonzero(data)\n",
        "            organ_files.append((file.replace('.nii.gz', ''), non_zero_voxels))\n",
        "\n",
        "    # Sort by voxel count (largest organs first)\n",
        "    organ_files.sort(key=lambda x: x[1], reverse=True)\n",
        "    for organ_name, voxel_count in organ_files:\n",
        "        print(f\"  {organ_name}: {voxel_count:,} voxels\")\n",
        "\n",
        "    print(f\"\\nMain segmentation file: segmentations.nii.gz\")\n",
        "    print(f\"Total files created: {len(organ_files) + 1}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during segmentation: {e}\")\n",
        "    print(\"This might be due to:\")\n",
        "    print(\"1. Model not available for the specified dataset\")\n",
        "    print(\"2. Input image format issues\")\n",
        "    print(\"3. Memory constraints\")\n",
        "\n",
        "    # Fallback: try with a different model configuration\n",
        "    print(\"\\nTrying with basic STU-Net model...\")\n",
        "    try:\n",
        "        model = medim.create_model(\"STU-Net-S\")\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "        print(\"Basic model loaded - you may need to adapt the preprocessing/postprocessing\")\n",
        "    except Exception as e2:\n",
        "        print(f\"Fallback also failed: {e2}\")\n",
        "\n",
        "# Note: Empty files are NOT removed - all organ files are preserved\n",
        "# even if they have zero segmented voxels (different from TotalSegmentator behavior)\n",
        "print(\"Processing complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}